{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be858957",
   "metadata": {},
   "source": [
    "### <div id=\"py\"> Working with different file formats </div>\n",
    "\n",
    "\n",
    "\n",
    "- JSON (java script object notation)\n",
    "- CSV (Command Seperated Values)\n",
    "- Excel\n",
    "- Avro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ec6af",
   "metadata": {},
   "source": [
    "### Data comes in various forms\n",
    "\n",
    "<img src=\"images/data_gen.jpeg\">\n",
    "\n",
    "As a data person you will deal with various type of data and it's important to learn how to handle these file formats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96639378",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Working in JSON files\n",
    "\n",
    "***\n",
    "Since its inception, JSON has quickly become the de facto standard for information exchange. \n",
    "\n",
    "Chances are you’re here because you need to transport some data from here to there. Perhaps you’re gathering information through an API or storing your data in a document database. \n",
    "\n",
    "One way or another, you’re up to your neck in JSON, and you’ve got to Python your way out.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4945d9c7",
   "metadata": {},
   "source": [
    "## A (Very) Brief History of JSON\n",
    "\n",
    "JSON stangs for JavaScript Object Notation was inspired by a subset of the JavaScript programming language dealing with object literal syntax. \n",
    "\n",
    "Ultimately, the community at large adopted JSON because it’s easy for both humans and machines to create and understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa222af9",
   "metadata": {},
   "source": [
    "### Look, it’s JSON!\n",
    "```\n",
    "{\n",
    "    \"firstName\": \"Jane\",\n",
    "    \"lastName\": \"Doe\",\n",
    "    \"hobbies\": [\"running\", \"sky diving\", \"singing\"],\n",
    "    \"age\": 35,\n",
    "    \"children\": [\n",
    "        {\n",
    "            \"firstName\": \"Alice\",\n",
    "            \"age\": 6\n",
    "        },\n",
    "        {\n",
    "            \"firstName\": \"Bob\",\n",
    "            \"age\": 8\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceafc60f",
   "metadata": {},
   "source": [
    "### Does this look similar to something?\n",
    "\n",
    "YES! Python **dictionary!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff0b925",
   "metadata": {},
   "source": [
    "### Writing JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19cba507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "481ec6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"president\": {\n",
    "        \"name\": \"Zaphod Beeblebrox\",\n",
    "        \"species\": \"Betelgeusian\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cd43843",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_file.json\", \"w\") as write_file:\n",
    "    json.dump(data, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a25a4",
   "metadata": {},
   "source": [
    " Note that `dump()` takes two positional arguments:\n",
    " 1. the data object to be serialized, and\n",
    " 2. the file-like object to which the bytes will be written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae9f99b",
   "metadata": {},
   "source": [
    "### Reading JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60eade2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_file.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6c5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4880e5c1",
   "metadata": {},
   "source": [
    "### You can also read JSON as DataFrame in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3448afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jsonStr = '''{\"Index0\":{\"Courses\": \"Pandas\",\"Discount\": \"1200\"},\n",
    "           \"Index1\":{\"Courses\": \"Hadoop\",\"Discount\": \"1500\"},\n",
    "           \"Index2\":{\"Courses\": \"Spark\",\"Discount\": \"1800\"}\n",
    "          }'''\n",
    "\n",
    "# Convert JSON to DataFrame Using read_json()\n",
    "df2 = pd.read_json(jsonStr, orient ='index')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0097b560",
   "metadata": {},
   "source": [
    "### Convert Dict To DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bceead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['president']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84371c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df3 = pd.DataFrame.from_dict(data, orient ='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b0503",
   "metadata": {},
   "source": [
    "## Working with CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee495711",
   "metadata": {},
   "source": [
    "A CSV file (Comma Separated Values file) is a type of plain text file that uses specific structuring to arrange tabular data. \n",
    "\n",
    "It’s a plain text file that has data separated by commas!\n",
    "\n",
    "```\n",
    "column 1 name,column 2 name, column 3 name\n",
    "first row data 1,first row data 2,first row data 3\n",
    "second row data 1,second row data 2,second row data 3\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40170091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/hrdata.csv', index_col='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c610f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35cb4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/hrdata.csv', index_col='Name', parse_dates=['Hire Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceed2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/hrdata_modified.csv')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e220c9",
   "metadata": {},
   "source": [
    "## Working with Excel Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f022f",
   "metadata": {},
   "source": [
    "Excel spreadsheets are one of those things you might have to deal with at some point. Either it’s because your boss loves them or because marketing needs them, and you might have to learn how to work with spreadsheets.\n",
    "\n",
    "Many companies still prefer using Excel files for their data storage and analysis, as a data expert you should know how to handle these files programatically!\n",
    "\n",
    "To work with Excel files we have package in python `openpyxl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8954655",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007e215",
   "metadata": {},
   "source": [
    "### Basics of Excel\n",
    "\n",
    "<img src=\"images/excel.png\" width=550>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37ea8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "\n",
    "workbook = Workbook()\n",
    "sheet = workbook.active\n",
    "\n",
    "sheet[\"A1\"] = \"hello\"\n",
    "sheet[\"B1\"] = \"world!\"\n",
    "\n",
    "workbook.save(filename=\"hello_world.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading excel file\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "workbook = load_workbook(filename=\"data/sample-xlsx-file.xlsx\")\n",
    "workbook.sheetnames\n",
    "['Sheet 1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6576d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = workbook.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c837c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet[\"A1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet[\"A2\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f785b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet.cell(row=10, column=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd98ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet.cell(row=3, column=3).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1e0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet[\"A1:C2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ba25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in sheet.iter_rows(values_only=True):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce2761",
   "metadata": {},
   "source": [
    "### You can read Excel file as DataFrame using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96673c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_df = pd.read_excel('data/sample-xlsx-file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4129976",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1042994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_df.to_excel('data/sample-xlsx-file-modifeid.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad8c3c2",
   "metadata": {},
   "source": [
    "## Working with AVRO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58db039",
   "metadata": {},
   "source": [
    "Apache Avro is a data serialization format. We can store data as `.avro` files on disk. \n",
    "\n",
    "Avro files are typically used with Spark but Spark is completely independent of Avro.\n",
    "\n",
    "Avro is a row-based format that is suitable for evolving data schemas. One benefit of using Avro is that schema and metadata travels with the data.\n",
    "\n",
    "If you have an .avro file, you have the schema of the data as well. \n",
    "\n",
    "The Apache Avro Specification provides easy-to-read yet detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78034bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install avro-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fefc748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3 with `avro-python3` package available\n",
    "import copy\n",
    "import json\n",
    "import avro\n",
    "from avro.datafile import DataFileWriter, DataFileReader\n",
    "from avro.io import DatumWriter, DatumReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0b82b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Note that we combined namespace and name to get \"full name\"\n",
    "schema = {\n",
    "    'name': 'avro.example.User',\n",
    "    'type': 'record',\n",
    "    'fields': [\n",
    "        {'name': 'name', 'type': 'string'},\n",
    "        {'name': 'age', 'type': 'int'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Parse the schema so we can use it to write the data\n",
    "schema_parsed = avro.schema.Parse(json.dumps(schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd70674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11cbe87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write data to an avro file\n",
    "with open('users.avro', 'wb') as f:\n",
    "    writer = DataFileWriter(f, DatumWriter(), schema_parsed)\n",
    "    writer.append({'name': 'Pierre-Simon Laplace', 'age': 77})\n",
    "    writer.append({'name': 'John von Neumann', 'age': 53})\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814999d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read data from an avro file\n",
    "with open('users.avro', 'rb') as f:\n",
    "    reader = DataFileReader(f, DatumReader())\n",
    "    metadata = copy.deepcopy(reader.meta)\n",
    "    schema_from_file = json.loads(metadata['avro.schema'])\n",
    "    users = [user for user in reader]\n",
    "    reader.close()\n",
    "\n",
    "print(f'Schema that we specified:\\n {schema}')\n",
    "print(f'Schema that we parsed:\\n {schema_parsed}')\n",
    "print(f'Schema from users.avro file:\\n {schema_from_file}')\n",
    "print(f'Users:\\n {users}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7a488",
   "metadata": {},
   "source": [
    "### Reading Avro Using Pandas\n",
    "\n",
    "Avro format simply requires a schema and a list of records. We don’t need a dataframe to handle Avro files. \n",
    "\n",
    "However, we can write a `pandas` dataframe into an Avro file or read an Avro file into a `pandas` dataframe. \n",
    "\n",
    "To begin with, we can always represent a dataframe as a list of records and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ddfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandavro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e8767509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import pandas as pd\n",
    "import pandavro as pdx\n",
    "from avro.datafile import DataFileReader\n",
    "from avro.io import DatumReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to be saved\n",
    "users = [{'name': 'Pierre-Simon Laplace', 'age': 77},\n",
    "         {'name': 'John von Neumann', 'age': 53}]\n",
    "users_df = pd.DataFrame.from_records(users)\n",
    "print(users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf12af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdx.to_avro('data/users_test.avro', users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0237ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data back\n",
    "users_df_redux = pdx.from_avro('data/users_test.avro')\n",
    "print(type(users_df_redux))\n",
    "# <class 'pandas.core.frame.DataFrame'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7256cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the schema for \"users.avro\"\n",
    "with open('users.avro', 'rb') as f:\n",
    "    reader = DataFileReader(f, DatumReader())\n",
    "    metadata = copy.deepcopy(reader.meta)\n",
    "    schema_from_file = json.loads(metadata['avro.schema'])\n",
    "    reader.close()\n",
    "print(schema_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91be078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
